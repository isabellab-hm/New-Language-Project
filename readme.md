Overall, my experience with learning a novel programming language (Python) and developing a computer vision project leveraging Python's OpenCV library was a success. In the beginning of our project time line, I had a difficult time developing a concrete project idea. As you may notice in my project code history, my original idea was to create an OpenCV-powered Attendance monitor that used real-time facial recognition to recongize people in the room, and possible create an inventory or list that would store all the people's name (allowing the camera to identify people it had previously recognized). Here are the sources I used to achieve this and get started with Open CV and Python: (1) https://docs.opencv.org/4.x/dd/d43/tutorial_py_video_display.html (2) https://github.com/arunponnusamy/cvlib, and (3) https://www.geeksforgeeks.org/python-opencv-cv2-puttext-method/. However, this initial project proved unsatisfactory for me, as I was not able to successfully run my program on my iPhone without the usage of third party application. This failure caused me to pivot the direction of my project. Instead, I decided to develop a program with cv2 and cvzone–two computer vision packages–in order create a virtual keyboard that operate of distinct hand movements. This required me to implement a significant amount of coordinate/hand tracking features in order to achieve this. To get me started on this project, I referenced this Youtube Video (https://www.youtube.com/watch?v=jzXZVFqEE2I&t=3111s) and MediaPipe's website (https://ai.google.dev/edge/mediapipe/solutions/vision/hand_landmarker)
in order to guide me through the early stages of my project. I also used this for importing the playsound library: (https://pypi.org/project/playsound/). Then, once I completely understood all the different working elements of my project, I was able to code independently (without the aid of online resources) in order to bring my project to the next level.
